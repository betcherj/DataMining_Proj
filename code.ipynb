{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import weka.core.jvm as jvm\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Classifier\n",
    "from weka.classifiers import Evaluation\n",
    "from weka.core.classes import Random\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import defaultdict\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.50470919506748\n",
      "\n",
      "Correctly Classified Instances       10145               98.5047 %\n",
      "Incorrectly Classified Instances       154                1.4953 %\n",
      "Kappa statistic                          0.982 \n",
      "Mean absolute error                      0.2226\n",
      "Root mean squared error                  0.3107\n",
      "Relative absolute error                 80.3187 %\n",
      "Root relative squared error             83.4718 %\n",
      "Total Number of Instances            10299     \n",
      "\n",
      "=== Detailed Accuracy By Class ===\n",
      "\n",
      "                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class\n",
      "                 0.960    0.009    0.961      0.960    0.960      0.951    0.991     0.944     STANDING\n",
      "                 0.958    0.009    0.957      0.958    0.957      0.948    0.986     0.930     SITTING\n",
      "                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     LAYING\n",
      "                 1.000    0.000    0.999      1.000    0.999      0.999    1.000     0.999     WALKING\n",
      "                 0.999    0.000    1.000      0.999    1.000      1.000    1.000     1.000     WALKING_DOWNSTAIRS\n",
      "                 0.999    0.000    0.999      0.999    0.999      0.999    1.000     0.999     WALKING_UPSTAIRS\n",
      "Weighted Avg.    0.985    0.003    0.985      0.985    0.985      0.982    0.996     0.977     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jvm.start()\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "data = loader.load_file(\"human_activity.arff\")\n",
    "data.class_is_last()\n",
    "cls = Classifier(classname=\"weka.classifiers.functions.SMO\")\n",
    "evl = Evaluation(data)\n",
    "evl.crossvalidate_model(cls, data, 10, Random(1))\n",
    "\n",
    "print(evl.percent_correct)\n",
    "print(evl.summary())\n",
    "print(evl.class_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"human_activity.csv\").drop('Unnamed: 0',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(\"label\", 1).values\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_test(classifier):\n",
    "    total_accuracy = 0\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        classifier.fit(x_train, y_train)\n",
    "        y_pred = classifier.predict(x_test)\n",
    "        accuracy = accuracy_score(y_pred, y_test)\n",
    "        print(accuracy)\n",
    "        total_accuracy += accuracy\n",
    "    return total_accuracy/n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP :\n",
      "0.9494145994143637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression :\n",
      "0.9612602026622407\n",
      "KNN :\n",
      "0.899118952078726\n",
      "SVC :\n",
      "0.9531041555661387\n",
      "RandomForestClassifier :\n",
      "0.7128909782767578\n",
      "AdaBoostClassifier :\n",
      "0.5437415184107659\n",
      "GaussianNB :\n",
      "0.727261654964942\n",
      "CatBoostClassifier :\n",
      "0.9495117339456896\n",
      "RandomForestClassifier :\n",
      "0.8788266525837315\n",
      "BernoulliNB :\n",
      "0.8339649749855006\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "        MLPClassifier(alpha=1),\n",
    "        LogisticRegression(),\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"linear\", C=0.025),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB(),\n",
    "        CatBoostClassifier(iterations=500, learning_rate=0.3, depth=5, loss_function='MultiClass', classes_count=6, logging_level='Silent', l2_leaf_reg=2, thread_count=4),\n",
    "        RandomForestClassifier(n_estimators=70, max_depth=5, max_features=0.8, n_jobs=4, class_weight='balanced'),\n",
    "        BernoulliNB(),\n",
    "    ]\n",
    "names = [\n",
    "    \"MLP\",\n",
    "    \"logistic regression\",\n",
    "    \"KNN\",\n",
    "    \"SVC\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"GaussianNB\",\n",
    "    \"CatBoostClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"BernoulliNB\"\n",
    "]\n",
    "for name,classifier in zip(names,classifiers):\n",
    "    accuracy = k_fold_test(classifier) \n",
    "    print(name+ \" :\")\n",
    "    print(accuracy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y,kernel, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(SVC(kernel=kernel), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = svc_param_selection(x,y,'poly',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001, 'gamma': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9667944181833621"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_accuracy = k_fold_test(SVC(kernel=\"poly\",C=.001,gamma=1))\n",
    "poly_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_best_params = svc_param_selection(x,y,'linear',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9609689876790034\n"
     ]
    }
   ],
   "source": [
    "linear_accuracy = k_fold_test(SVC(kernel=\"linear\",C=10,gamma=.001))\n",
    "linear_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_best_params = svc_param_selection(x,y,'rbf',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.01}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9648527649617407"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_accuracy = k_fold_test(SVC(kernel=\"rbf\",C=10,gamma=.01))\n",
    "rbf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 129.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'bootstrap': [True, False], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'min_samples_leaf': [1, 2, 4], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'max_features': ['auto', 'sqrt'], 'min_samples_split': [2, 5, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9395106003566476\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(bootstrap=False,max_depth=50,max_features='auto',min_samples_leaf=1,min_samples_split=2,n_estimators=1000)\n",
    "random_forest_accuracy = k_fold_test(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_classifiers = [\n",
    "    SVC(kernel=\"poly\",C=.001,gamma=1,probability=True),\n",
    "    RandomForestClassifier(bootstrap=False,max_depth=50,max_features='auto',min_samples_leaf=1,min_samples_split=2,n_estimators=1000),\n",
    "    LogisticRegression(),\n",
    "    KNeighborsClassifier(3),\n",
    "    CatBoostClassifier(iterations=100,depth=5, loss_function='MultiClass', classes_count=6, logging_level='Silent', l2_leaf_reg=2, thread_count=8)\n",
    "    ]\n",
    "final_names = [\"svc\",\"random forest\",\"logistic regression\", \"KNN\", \"Catboost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_trained_classifier(clf_index,clf,X_te,num_labels,level1,te_idx):\n",
    "    predictions = clf.predict_proba(X_te)\n",
    "    for label_index in range(num_labels):\n",
    "        current = clf_index*num_labels+label_index\n",
    "        level1[te_idx,current] = predictions[:,label_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_data(X,y,classifiers):\n",
    "    num_labels = len(set(y))\n",
    "    kf = KFold(n_splits=10)\n",
    "    level1 = np.zeros((X.shape[0], len(classifiers)*num_labels))\n",
    "    split_index = 0\n",
    "    for tr_idx, te_idx in kf.split(X):\n",
    "        split_index+=1\n",
    "        print(\"Split index {}\".format(split_index))\n",
    "        X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
    "        X_te, y_te = X[te_idx], y[te_idx]\n",
    "        for clf_index,clf in enumerate(classifiers):\n",
    "            print(\"Clf index {}\".format(clf_index))\n",
    "            clf.fit(X_tr,y_tr)\n",
    "            use_trained_classifier(clf_index,clf,X_te,num_labels,level1,te_idx)\n",
    "    return level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split index 1\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 2\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 3\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 4\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 5\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 6\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 7\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 8\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 9\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 10\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 1\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 2\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 3\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 4\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 5\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 6\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 7\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 8\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 9\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n",
      "Split index 10\n",
      "Clf index 0\n",
      "Clf index 1\n",
      "Clf index 2\n",
      "Clf index 3\n",
      "Clf index 4\n"
     ]
    }
   ],
   "source": [
    "level1_train = get_level_data(X_train,y_train,final_classifiers)\n",
    "level1_test = get_level_data(X_test,y_test,final_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_meta_classifiers(level1_train,y_train,level1_test,y_test):\n",
    "    meta_clfs = [\n",
    "        RidgeClassifier(normalize=True, class_weight='balanced')\n",
    "    ]\n",
    "    for meta_clf in meta_clfs:\n",
    "        meta_clf.fit(level1_train, y_train)\n",
    "        meta_preds = meta_clf.predict(level1_test)\n",
    "        total_accuracy = accuracy_score(meta_preds, y_test)\n",
    "        print(total_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.962135922330097\n"
     ]
    }
   ],
   "source": [
    "test_meta_classifiers(level1_train,y_train,level1_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate((level1_train,X_train),axis=1)\n",
    "test =  np.concatenate((level1_test,X_test),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9631067961165048\n"
     ]
    }
   ],
   "source": [
    "test_meta_classifiers(train,y_train,test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level1_test(X_train,y_train,X_test,classifiers):\n",
    "    num_labels = len(set(y_train))\n",
    "    kf = KFold(n_splits=10)\n",
    "    level1 = np.zeros((X_test.shape[0], len(classifiers)*num_labels))\n",
    "    split_index = 0\n",
    "    for clf_index,clf in enumerate(classifiers):\n",
    "        clf.fit(X_train,y_train)\n",
    "        predictions = clf.predict_proba(X_test)\n",
    "        for label_index in range(num_labels):\n",
    "            current = clf_index*num_labels+label_index\n",
    "            level1[:,current] = predictions[:,label_index]\n",
    "    return level1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "level1_test_full_train = get_level1_test(X_train,y_train,X_test,final_classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996116504854369\n"
     ]
    }
   ],
   "source": [
    "test_meta_classifiers(level1_train,y_train,level1_test_full_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def plot_decision_boundaries(models,titles,meta):    \n",
    "    # import some data to play with\n",
    "    iris = datasets.load_iris()\n",
    "    # Take the first two features. We could avoid this by using a two-dim dataset\n",
    "    X_iris = iris.data[:, :2]\n",
    "    y_iris = iris.target\n",
    "\n",
    "    # we create an instance of SVM and fit out data. We do not scale our\n",
    "    # data since we want to plot the support vectors\n",
    "    C = 1.0  # SVM regularization parameter\n",
    "    models = (clf.fit(X_iris, y_iris) for clf in models)\n",
    "    # Set-up 2x2 grid for plotting.\n",
    "    fig, sub = plt.subplots(2, 2)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    X0, X1 = X_iris[:, 0], X_iris[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "    for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "        plot_contours(ax, clf, xx, yy,\n",
    "                      cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xlabel('Sepal length')\n",
    "        ax.set_ylabel('Sepal width')\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_meta_model(names,classifiers,x,y):\n",
    "    model_to_accuracy = defaultdict(list)\n",
    "    split_index = 0\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        print(split_index)\n",
    "        split_index+=1\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        for name,classifier in zip(names,classifiers):\n",
    "            classifier.fit(x_train, y_train)\n",
    "            y_pred = classifier.predict(x_test)\n",
    "            accuracies[name].append(accuracy_score(y_pred, y_test))\n",
    "        level1_train = get_level_data(x_train,y_train,classifiers)\n",
    "        level1_test = get_level_data(x_test,y_test,classifiers)\n",
    "        meta_accuracy = test_meta_classifiers(level1_train,y_train,level1_test,y_test)\n",
    "        accuracies[\"meta_learner\"].append(meta_accuracy)\n",
    "    return model_to_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracies(model_to_accuracy,p=.05):\n",
    "    meta_learner_accuracies = model_to_accuracy[\"meta_learner\"]\n",
    "    for model in model_to_accuracy:\n",
    "        if model!=\"meta_learner\":\n",
    "            p_score = stats.ttest_rel(meta_learner_accuracies,model_to_accuracy[model])[1]\n",
    "            if p_score<.05:\n",
    "                print(\"There is a significant difference between the meta learner and model {}\".format(model))\n",
    "            else:\n",
    "                print(\"There is no significant difference between the meta learner and model {}\".format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4d83fddd3f4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbreast_cancer_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreast_cancer_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_breast_cancer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbreast_cancer_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_meta_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_classifiers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreast_cancer_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbreast_cancer_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "datasetsast_cancer_x,breast_cancer_y = datasets.load_breast_cancer() \n",
    "breast_cancer_accuracies = test_meta_model(final_names,final_classifiers,breast_cancer_x,breast_cancer_y)\n",
    "breast_cancer_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies(breast_cancer_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_x,iris_y = datasets.load_iris()\n",
    "iris_accuracies = test_meta_model(final_names,final_classifiers,breast_cancer_x,breast_cancer_y)\n",
    "iris_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracies(iris_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
